{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To analyze all the data at once, I created a dataframe for all the CSV files.\n",
    "#Pro: Allows for analysis of all three million tweets at once\n",
    "#Con: Large dataset might hinder the speed of analysis due to comp limitations. \n",
    "path = 'data'\n",
    "filenames = glob.glob(path + '/*csv')\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "\n",
    "IRA2016 = pd.concat(dfs, ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potential Analysis:\n",
    "#Hashtag trend analysis to identify themes and propaganda target audiences.\n",
    "#Top Propaganda Agent\n",
    "#Bot classification for Top 20\n",
    "#Effectiveness Rating \n",
    "IRA2016.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Propaganda_Agents = IRA2016['author'].unique()\n",
    "len(Propaganda_Agents)\n",
    "# 2843 unique propaganda agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_counts = IRA2016['followers'].value_counts()\n",
    "follower_counts.head(30)\n",
    "followers_by_author = IRA2016.groupby('author')['followers'].max()\n",
    "followers_by_author_sorted = followers_by_author.sort_values(ascending=False)\n",
    "Top_10_By_Followers = followers_by_author_sorted.head(10)\n",
    "Top_30_By_Followers = followers_by_author_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_10_By_Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_handles = ['NOVOSTIMSK', 'TEN_GOP', 'NOVOSTISPB', 'KADIROVRUSSIA', 'MAXDEMENTIEV',\n",
    "                   'LAVROVMUESLI', 'JENN_ABRAMS', 'PAMELA_MOORE13', 'TODAYNYCITY', 'ELEVEN_GOP']\n",
    "follower_counts = [251276, 145244, 113638, 110155, 103197, 72720, 71022, 70734, 62088, 59100]\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(twitter_handles, follower_counts, color='skyblue')\n",
    "plt.xlabel('Twitter Handles')\n",
    "plt.ylabel('Follower Count')\n",
    "plt.title('Top 10 Followed Russian IRA Accounts')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_counts = IRA2016['author'].value_counts()\n",
    "\n",
    "# Get the user with the most tweets\n",
    "most_tweets_user = tweet_counts.idxmax()\n",
    "num_tweets = tweet_counts.max()\n",
    "\n",
    "most_tweets_user\n",
    "#num_tweets\n",
    "top10_agents = tweet_counts.head(10)\n",
    "top10_agents\n",
    "\n",
    "top30_agents = tweet_counts.head(30)\n",
    "print(top30_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usernames and follower counts\n",
    "users = ['EXQUOTE', 'SCREAMYMONKEY', 'AMELIEBALDWIN', 'WORLDNEWSPOLI', 'TODAYPITTSBURGH',\n",
    "         'SPECIALAFFAIR', 'SEATTLE_POST', 'FINDDIET', 'KANSASDAILYNEWS', 'ROOMOFRUMOR']\n",
    "tweet_counts_counts = [59174, 44001, 35261, 35155, 33602, 32556, 30793, 29038, 28806, 28351]\n",
    "\n",
    "# Plotting histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(users, tweet_counts_counts, color='skyblue')\n",
    "plt.xlabel('Twitter Handles')\n",
    "plt.ylabel('Tweet Count')\n",
    "plt.title('Top 10 Russian IRA Total Tweets')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of usernames to keep\n",
    "users_to_keep = ['EXQUOTE', 'SCREAMYMONKEY', 'AMELIEBALDWIN', 'WORLDNEWSPOLI', 'TODAYPITTSBURGH',\n",
    "                 'SPECIALAFFAIR', 'SEATTLE_POST', 'FINDDIET', 'KANSASDAILYNEWS', 'ROOMOFRUMOR']\n",
    "\n",
    "# Filter the DataFrame to keep only the rows where the username is in the list of users to keep\n",
    "Top_10_Agents = IRA2016[IRA2016['author'].isin(users_to_keep)]\n",
    "\n",
    "Top_10_Agents.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_keep = ['EXQUOTE', 'SCREAMYMONKEY', 'AMELIEBALDWIN', 'WORLDNEWSPOLI', 'TODAYPITTSBURGH',\n",
    "    'SPECIALAFFAIR', 'SEATTLE_POST', 'FINDDIET', 'KANSASDAILYNEWS', 'ROOMOFRUMOR',\n",
    "    'DAILYSANFRAN', 'WORLDOFHASHTAGS', 'COVFEFENATIONUS', 'JENN_ABRAMS', 'CHICAGODAILYNEW',\n",
    "    'RIAFANRU', 'POLITICS_T0DAY', 'FUNDDIET', 'BERLINBOTE', 'CHESPLAYSCHESS',\n",
    "    'TODAYNYCITY', 'ONLINECLEVELAND', 'HYDDROX', 'OLD_NEW_POLICY', 'TODAYINSYRIA',\n",
    "    'NEWORLEANSON', 'ARM_2_ALAN', 'CHRIXMORGAN', 'DAILYSANDIEGO', 'DAILYLOSANGELES']\n",
    "Top_30_Agents = IRA2016[IRA2016['author'].isin(users_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "Top_10_Agents['content'] = Top_10_Agents['content'].astype(str)\n",
    "# Extract hashtags from each tweet in the DataFrame\n",
    "hashtags_list = Top_10_Agents['content'].apply(lambda x: re.findall(r'#(\\w+)', x))\n",
    "\n",
    "# Flatten the list of lists into a single list of hashtags\n",
    "hashtags = [tag for sublist in hashtags_list for tag in sublist]\n",
    "\n",
    "# Remove duplicate hashtags\n",
    "#unique_hashtags = list(set(hashtags))\n",
    "\n",
    "#Count the hashtags\n",
    "hashtags_counts = pd.Series(hashtags).value_counts()\n",
    "\n",
    "# Get the most used hashtag\n",
    "most_used_hashtag = hashtags_counts.idxmax()\n",
    "most_used_hashtag_count = hashtags_counts.max()\n",
    "\n",
    "#print(\"Unique hashtags used in the dataset:\", unique_hashtags)\n",
    "\n",
    "hashtags_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "Top_30_Agents['content'] = Top_30_Agents['content'].astype(str)\n",
    "# Extract hashtags from each tweet in the DataFrame\n",
    "hashtags_list = Top_30_Agents['content'].apply(lambda x: re.findall(r'#(\\w+)', x))\n",
    "\n",
    "# Flatten the list of lists into a single list of hashtags\n",
    "hashtags = [tag for sublist in hashtags_list for tag in sublist]\n",
    "\n",
    "# Remove duplicate hashtags\n",
    "#unique_hashtags = list(set(hashtags))\n",
    "\n",
    "#Count the hashtags\n",
    "hashtags_counts = pd.Series(hashtags).value_counts()\n",
    "\n",
    "# Get the most used hashtag\n",
    "most_used_hashtag = hashtags_counts.idxmax()\n",
    "most_used_hashtag_count = hashtags_counts.max()\n",
    "\n",
    "#print(\"Unique hashtags used in the dataset:\", unique_hashtags)\n",
    "\n",
    "hashtags_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_counts.head(20)\n",
    "#PJNET? Open source research indicated PJNET(Patriot Journalism Network) is involved in the use of twitter bots to propagate christian themed messaging.\n",
    "#Initial inspection of PJNET's website point to a creator named American proffesor named Leonard Witt\n",
    "#The network allow ordinary individuals to give over access to their twitter accounts for messaging \n",
    "#Potential IRA backstop unwhitting organization used to obtain seasoned twitter accounts to propagate propaganda\n",
    "#Or leverage by IRA to help amplify narratives\n",
    "#More research is needed to varify\n",
    "\n",
    "'''news                128757\n",
    "sports               48654\n",
    "politics             39748\n",
    "world                27561\n",
    "local                25890\n",
    "TopNews              15149\n",
    "MAGA                 14808\n",
    "BlackLivesMatter     12005\n",
    "tcot                 11492\n",
    "health               11492\n",
    "business             10851\n",
    "PJNET                10463\n",
    "новости              10325\n",
    "tech                  8232\n",
    "entertainment         7586\n",
    "top                   7417\n",
    "Cleveland             6710\n",
    "TopVideo              6547\n",
    "crime                 6505\n",
    "ISIS                  6219'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "IRA2016['content'] = IRA2016['content'].astype(str)\n",
    "# Extract hashtags from each tweet in the DataFrame\n",
    "hashtags_list = IRA2016['content'].apply(lambda x: re.findall(r'#(\\w+)', x))\n",
    "\n",
    "# Flatten the list of lists into a single list of hashtags\n",
    "hashtags = [tag for sublist in hashtags_list for tag in sublist]\n",
    "\n",
    "# Remove duplicate hashtags\n",
    "#unique_hashtags = list(set(hashtags))\n",
    "\n",
    "#Count the hashtags\n",
    "hashtags_counts = pd.Series(hashtags).value_counts()\n",
    "\n",
    "# Get the most used hashtag\n",
    "most_used_hashtag = hashtags_counts.idxmax()\n",
    "most_used_hashtag_count = hashtags_counts.max()\n",
    "\n",
    "#print(\"Unique hashtags used in the dataset:\", unique_hashtags)\n",
    "\n",
    "hashtags_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df = IRA2016['language'].value_counts()\n",
    "# 56 total languages \n",
    "language_df = language_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of languages\n",
    "plt.figure(figsize=(10, 6))\n",
    "language_df.plot(kind='bar')\n",
    "plt.title('Top 10 of 56 Languages From Russian IRA Tweets')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Number of Tweets (Millions)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRA2016.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df = IRA2016['region'].value_counts()\n",
    "# 36 regions \n",
    "region_df.idxmax()\n",
    "region_df = region_df.head(10)\n",
    "# Plot the distribution of languages\n",
    "plt.figure(figsize=(10, 6))\n",
    "region_df.plot(kind='bar')\n",
    "plt.title('Top 10 of 36 Regions From Russian IRA Tweets')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Number of Tweets (Millions)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA CLEANING / DATA FORMATING\n",
    "#DROP COLUMNS: tco1_step1, tco1_step2, tco_step3, external_author_id, harvested_date, new_june_2018, alt_external_id, tweet_id\n",
    "cols_to_drop = ['tco1_step1', 'tco2_step1', 'tco3_step1', 'external_author_id', 'harvested_date', 'new_june_2018', 'alt_external_id', 'tweet_id', 'article_url', 'retweet', 'post_type']\n",
    "filtered_IRA = IRA2016.drop(cols_to_drop, axis=1)\n",
    "#Select only english language tweets\n",
    "filtered_IRA2 = filtered_IRA[filtered_IRA['language'] == 'English']\n",
    "#Drop language column\n",
    "filtered_IRA3 = filtered_IRA2.drop('language', axis=1)\n",
    "filtered_IRA3['account_type'].value_counts()\n",
    "#Drop account type, this is essentially a duplicate of 'account_category'\n",
    "filtered_IRA4 = filtered_IRA3.drop('account_type', axis=1) \n",
    "\n",
    "filtered_IRA4.T['account_activity'] = filtered_IRA4['updates']\n",
    "filtered_IRA4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean number of followers for each author\n",
    "mean_followers = filtered_IRA4.groupby('author')['followers'].mean()\n",
    "\n",
    "# Count the number of tweets by each author\n",
    "tweet_counts = filtered_IRA4['author'].value_counts()\n",
    "\n",
    "# Calculate the total propagation for each author\n",
    "filtered_IRA4['total_propagation'] = filtered_IRA4['author'].map(tweet_counts) * filtered_IRA4['author'].map(mean_followers)\n",
    "filtered_IRA5 = filtered_IRA4[filtered_IRA4['region'] == 'United States']\n",
    "\n",
    "# Create the 'top_performer' DataFrame\n",
    "top_performer = filtered_IRA5.drop_duplicates(subset='author')[['author', 'total_propagation', 'account_category']]\n",
    "\n",
    "# Reset the index if needed\n",
    "top_performer.reset_index(drop=True, inplace=True)\n",
    "top_performer.value_counts(ascending=False)\n",
    "\n",
    "#top_performer\n",
    "filtered_IRA5.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort 'top_performer' by total_propagation in descending order\n",
    "top_performer_sorted = top_performer.sort_values(by='total_propagation', ascending=False)\n",
    "\n",
    "# Plot the top 20 performers on a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_performer_sorted['author'].head(20), top_performer_sorted['total_propagation'].head(20), color='skyblue')\n",
    "plt.xlabel('Author')\n",
    "plt.ylabel('Total Propagation')\n",
    "plt.title('Top 20 Performers by Total Propagation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_IRA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_IRA5.drop('region', axis=1, inplace=True)\n",
    "most_active = filtered_IRA5.groupby('author')['updates'].max().sort_values(ascending=False).head(20)\n",
    "most_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_IRA5['Total_activity'] = filtered_IRA4['updates'].map(most_active)\n",
    "filtered_IRA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_updates_by_author = filtered_IRA5.groupby('author')['updates'].max()\n",
    "\n",
    "# Create a new DataFrame to store the result\n",
    "result_df = pd.DataFrame(max_updates_by_author).reset_index()\n",
    "\n",
    "# Rename the column to 'Total_Activity'\n",
    "result_df.rename(columns={'updates': 'Total_Activity'}, inplace=True)\n",
    "\n",
    "# Merge the result DataFrame with the original DataFrame based on 'author'\n",
    "filtered_IRA5 = pd.merge(filtered_IRA5, result_df, on='author', how='left')\n",
    "\n",
    "filtered_IRA5.rename(columns={'Total_Activity_x': 'Total_Activity'}, inplace=True)\n",
    "cols_to_drop = ['Total_activity', 'Total_Activity_y']\n",
    "filtered_IRA6 = filtered_IRA5.drop(columns=cols_to_drop, axis=1)\n",
    "filtered_IRA6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_IRA6['publish_date'] = pd.to_datetime(filtered_IRA6['publish_date'])\n",
    "\n",
    "# Extract date part from 'publish_date'\n",
    "filtered_IRA6['publish_date'] = filtered_IRA6['publish_date'].dt.date\n",
    "\n",
    "# Group by 'author' and date, and count the number of tweets for each group\n",
    "daily_tweet_counts = filtered_IRA6.groupby(['author', 'publish_date']).size().reset_index(name='daily_tweet_count')\n",
    "\n",
    "# Calculate the total number of days each author tweeted\n",
    "author_total_days = filtered_IRA6.groupby(['author', 'publish_date'])['publish_date'].nunique().reset_index(name='total_days')\n",
    "\n",
    "# Merge the total days each author tweeted back to the daily_tweet_counts DataFrame\n",
    "daily_tweet_counts = daily_tweet_counts.merge(author_total_days, on=['author', 'publish_date'], how='left')\n",
    "\n",
    "# Calculate the average daily tweets for each author\n",
    "daily_tweet_counts['average_daily_tweets'] = daily_tweet_counts['daily_tweet_count'] / daily_tweet_counts['total_days']\n",
    "\n",
    "# Merge the average daily tweets back to the original DataFrame\n",
    "df = filtered_IRA6.merge(daily_tweet_counts[['author', 'publish_date', 'average_daily_tweets']], on=['author', 'publish_date'], how='left')\n",
    "\n",
    "# Create a new column 'daily_tweet_count' containing the daily tweet count for each author and date\n",
    "filtered_IRA6 = filtered_IRA6.merge(daily_tweet_counts[['author', 'publish_date', 'daily_tweet_count']], on=['author', 'publish_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This imply the mean average tweet for all account is 179. Which is well above an expected rate for a user. \n",
    "filtered_IRA6['daily_tweet_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_total_days.describe()\n",
    "daily_tweet_counts.head(50)\n",
    "filtered_IRA6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample100 = filtered_IRA6.sample(100)\n",
    "sample1000 = filtered_IRA6.sample(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(content):\n",
    "    return re.findall(r'#(\\w+)', content)\n",
    "\n",
    "# Apply the function to extract hashtags and create a new column 'hashtags'\n",
    "sample1000['hashtags'] = sample1000['content'].apply(extract_hashtags)\n",
    "\n",
    "# Group by 'author' and count hashtags for each unique user\n",
    "author_group = sample1000.groupby('author')['hashtags'].sum().reset_index()\n",
    "\n",
    "# Count the occurrences of each hashtag for each user and get top 5 hashtags\n",
    "def top5_hashtags(hashtag_list):\n",
    "    hashtag_counts = pd.Series(hashtag_list).value_counts()\n",
    "    return dict(hashtag_counts.head(5))\n",
    "\n",
    "# Create a new column 'top_hashtags' with the top 5 hashtags and their counts\n",
    "author_group['top_hashtags'] = author_group['hashtags'].apply(top5_hashtags)\n",
    "\n",
    "# Fill NaN values with an empty dictionary\n",
    "author_group['top_hashtags'] = author_group['top_hashtags'].fillna({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
